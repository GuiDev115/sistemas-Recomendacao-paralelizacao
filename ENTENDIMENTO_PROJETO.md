# Entendimento Completo do Projeto
## Sistema de Recomenda√ß√£o Paralelo - Amazon

---

## üìã O QUE O PROJETO FAZ?

Este projeto implementa um **sistema de recomenda√ß√£o de produtos** similar ao usado pela Amazon, mas com foco em **paraleliza√ß√£o** para melhorar o desempenho.

### Funcionamento B√°sico

1. **Entrada**: Avalia√ß√µes de usu√°rios sobre produtos (ex: usu√°rio 1 deu nota 5 para produto 10)
2. **Processamento**: Calcula quais produtos s√£o similares entre si
3. **Sa√≠da**: Recomenda produtos para usu√°rios baseado em suas compras anteriores

### Exemplo Pr√°tico

```
Usu√°rio comprou: Celular Samsung
Sistema calcula: "Celular Samsung" √© similar a "Capa Samsung", "Fone Bluetooth"
Sistema recomenda: "Capa Samsung" e "Fone Bluetooth" para o usu√°rio
```

---

## üéØ PROBLEMA QUE RESOLVE

### Desafio Real da Amazon
- Milh√µes de produtos no cat√°logo
- Bilh√µes de intera√ß√µes usu√°rio-produto
- Necessidade de calcular similaridade entre **TODOS** os pares de produtos
- Para 10.000 produtos = 50 milh√µes de compara√ß√µes!

### Solu√ß√£o: Paraleliza√ß√£o
Em vez de fazer as compara√ß√µes uma por vez (sequencial), o projeto divide o trabalho entre m√∫ltiplos processadores, executando c√°lculos simultaneamente.

---

## üî¨ ALGORITMO IMPLEMENTADO

### Filtragem Colaborativa Item-Item

#### Passo 1: Calcular Similaridade de Cosseno
Para cada par de produtos (i, j), calcula qu√£o similares eles s√£o baseado nas avalia√ß√µes dos usu√°rios:

```
Similaridade(Produto_A, Produto_B) = 
    soma(avalia√ß√µes_A √ó avalia√ß√µes_B) / 
    (norma_A √ó norma_B)
```

**Exemplo:**
- Produto A: [5, 4, -, 5] (4 usu√°rios avaliaram)
- Produto B: [5, 5, -, 4]
- Similaridade ‚âà 0.98 (muito similares!)

#### Passo 2: Construir Matriz de Similaridade
Cria uma tabela com similaridade entre todos os produtos:

```
         Prod1  Prod2  Prod3
Prod1    1.00   0.85   0.23
Prod2    0.85   1.00   0.67
Prod3    0.23   0.67   1.00
```

#### Passo 3: Gerar Recomenda√ß√µes
Para um usu√°rio, pega os produtos que ele j√° avaliou e recomenda produtos similares que ele ainda n√£o comprou.

---

## üíª IMPLEMENTA√á√ïES

### 4 Vers√µes do C√≥digo

#### 1Ô∏è‚É£ **Sequencial** (`src/sequential/recommender.c`)
- Executa tudo em **1 processador**
- Baseline (refer√™ncia) para compara√ß√£o
- C√≥digo mais simples

#### 2Ô∏è‚É£ **OpenMP** (`src/openmp/recommender_omp.c`)
- Usa **diretivas #pragma** para paralelizar
- Mem√≥ria compartilhada
- **Mais simples** de implementar
- Melhor desempenho geral

```c
#pragma omp parallel for schedule(dynamic, 10)
for (int i = 0; i < num_items; i++) {
    // Cada thread processa alguns itens
}
```

#### 3Ô∏è‚É£ **Pthreads** (`src/pthreads/recommender_pthread.c`)
- Usa **threads POSIX** (controle manual)
- Mem√≥ria compartilhada
- Mais controle, mas mais complexo

```c
pthread_create(&threads[i], NULL, worker_function, &data[i]);
pthread_join(threads[i], NULL);
```

#### 4Ô∏è‚É£ **MPI** (`src/mpi/recommender_mpi.c`)
- Usa **passagem de mensagens**
- Mem√≥ria distribu√≠da
- Escala para **m√∫ltiplos computadores** (cluster)

```c
MPI_Bcast(data, size, MPI_FLOAT, 0, MPI_COMM_WORLD);  // Distribui dados
MPI_Gather(results, size, MPI_FLOAT, 0, ...);         // Coleta resultados
```

---

## üìä DADOS SINT√âTICOS

### Gerador de Dados (`scripts/generate_data.py`)

Cria avalia√ß√µes fict√≠cias de usu√°rios sobre produtos:

```
Formato: user_id item_id rating
Exemplo:
0 42 5.0    # Usu√°rio 0 deu nota 5 para item 42
1 10 4.5    # Usu√°rio 1 deu nota 4.5 para item 10
```

### Tamanhos Dispon√≠veis
- **Small**: 100 usu√°rios √ó 100 produtos = 1.000 avalia√ß√µes
- **Medium**: 500 √ó 500 = 10.000 avalia√ß√µes
- **Large**: 1.000 √ó 1.000 = 50.000 avalia√ß√µes
- **XLarge**: 2.000 √ó 2.000 = 100.000 avalia√ß√µes

---

## üß™ O QUE FAZ `make test`?

### Comando: `make test`

Executa um **teste r√°pido** (1 execu√ß√£o) de cada vers√£o com o dataset **small**:

```bash
make test
```

### Fluxo de Execu√ß√£o:

```
1. make all     ‚Üí Compila todas as 4 vers√µes
2. make data    ‚Üí Gera dados de teste (se n√£o existir)
3. Executa:
   ‚îú‚îÄ Sequencial       data/ratings_small.txt
   ‚îú‚îÄ OpenMP (4)       data/ratings_small.txt 4
   ‚îú‚îÄ Pthreads (4)     data/ratings_small.txt 4
   ‚îî‚îÄ MPI (4)          data/ratings_small.txt 4
```

### Sa√≠da Esperada:

```
=== Sequencial ===
Carregados: 100 usu√°rios, 100 itens, 1000 avalia√ß√µes
Tempo de execu√ß√£o: 0.0011 segundos
Top 10 recomenda√ß√µes para usu√°rio 0: ...

=== OpenMP (4 threads) ===
Tempo de execu√ß√£o: 0.0006 segundos  ‚Üê ~2x mais r√°pido!
Top 10 recomenda√ß√µes para usu√°rio 0: ...

=== Pthreads (4 threads) ===
Tempo de execu√ß√£o: 0.0007 segundos
...

=== MPI (4 processos) ===
Tempo de execu√ß√£o: 0.0008 segundos
...
```

### Objetivo do Teste:
- ‚úÖ Verificar que **todos** os programas compilam
- ‚úÖ Verificar que **todos** executam corretamente
- ‚úÖ Comparar **tempos de execu√ß√£o** rapidamente
- ‚úÖ Ver que a **paraleliza√ß√£o acelera** o processamento

---

## üî¨ O QUE FAZ `make benchmark`?

### Comando: `make benchmark`

Executa experimentos **completos** para an√°lise cient√≠fica:

```bash
make benchmark  # Demora ~30 minutos
```

### Fluxo de Execu√ß√£o:

```
1. Para cada vers√£o (Sequencial, OpenMP, Pthreads, MPI):
   ‚îú‚îÄ Para cada n√∫mero de threads (1, 2, 4, 8):
   ‚îÇ  ‚îî‚îÄ Executa 10 vezes
   ‚îÇ     ‚îú‚îÄ Execu√ß√£o 1
   ‚îÇ     ‚îú‚îÄ Execu√ß√£o 2
   ‚îÇ     ‚îî‚îÄ ...
   ‚îÇ     ‚îî‚îÄ Execu√ß√£o 10
   ‚îî‚îÄ Calcula estat√≠sticas:
      ‚îú‚îÄ M√©dia
      ‚îú‚îÄ Desvio padr√£o
      ‚îú‚îÄ Intervalo de confian√ßa 95%
      ‚îú‚îÄ Speedup
      ‚îú‚îÄ Efici√™ncia
      ‚îî‚îÄ Karp-Flatt (fra√ß√£o serial)
```

### Sa√≠da:
- Arquivos em `results/` com tempos de execu√ß√£o
- Usado depois por `make analyze` para gerar gr√°ficos

---

## üìà O QUE FAZ `make analyze`?

### Comando: `make analyze`

Analisa os resultados do benchmark e **gera gr√°ficos**:

```bash
make analyze
```

### Gr√°ficos Gerados (em `results/`):

1. **execution_time.png**
   - Tempo vs N√∫mero de Threads
   - Mostra como o tempo diminui com mais threads

2. **speedup.png**
   - Speedup vs N√∫mero de Threads
   - Mostra quantas vezes mais r√°pido ficou
   - Linha "ideal" para compara√ß√£o

3. **efficiency.png**
   - Efici√™ncia vs N√∫mero de Threads
   - Mostra se os recursos est√£o sendo bem aproveitados

4. **karp_flatt.png**
   - Fra√ß√£o Serial vs Threads
   - Estima quanto c√≥digo n√£o pode ser paralelizado

5. **results_table.tex**
   - Tabela LaTeX formatada para o relat√≥rio

---

## üéì M√âTRICAS CALCULADAS

### 1. Tempo de Execu√ß√£o
- **Defini√ß√£o**: Quanto tempo o programa leva para executar
- **C√°lculo**: M√©dia de 10 execu√ß√µes
- **Exemplo**: 2.5 segundos

### 2. Speedup (Sp)
- **Defini√ß√£o**: Quantas vezes mais r√°pido ficou
- **F√≥rmula**: `Sp = Tempo_Sequencial / Tempo_Paralelo`
- **Ideal**: Linear (Sp = p), ex: 4 threads = 4x mais r√°pido
- **Exemplo**: Se sequencial = 4s e paralelo = 1s ‚Üí Speedup = 4x

### 3. Efici√™ncia (Ep)
- **Defini√ß√£o**: Qu√£o bem os recursos est√£o sendo usados
- **F√≥rmula**: `Ep = Speedup / N√∫mero_de_Threads`
- **Ideal**: 100% (Ep = 1.0)
- **Exemplo**: Speedup 3.2x com 4 threads ‚Üí Efici√™ncia = 80%

### 4. Karp-Flatt (e)
- **Defini√ß√£o**: Estimativa da fra√ß√£o de c√≥digo que n√£o pode ser paralelizada
- **F√≥rmula**: `e = (1/Sp - 1/p) / (1 - 1/p)`
- **Ideal**: Pr√≥ximo de 0 (c√≥digo altamente paraleliz√°vel)
- **Exemplo**: e = 0.05 significa 5% do c√≥digo √© sequencial

### 5. Intervalo de Confian√ßa (95%)
- **Defini√ß√£o**: Margem de erro estat√≠stica
- **Uso**: Tempo m√©dio ¬± margem
- **Exemplo**: 2.5s ¬± 0.1s (entre 2.4s e 2.6s)

---

## üîÑ FLUXO COMPLETO DO PROJETO

### Fase 1: Prepara√ß√£o
```
1. Verificar sistema        ./check.sh
2. Compilar programas       make all
3. Gerar dados              make data
```

### Fase 2: Testes R√°pidos
```
4. Teste b√°sico             make test
   ‚îî‚îÄ Verifica funcionamento b√°sico
```

### Fase 3: Experimentos Completos
```
5. Benchmark completo       make benchmark
   ‚îú‚îÄ 10 execu√ß√µes √ó 4 threads √ó 4 vers√µes
   ‚îî‚îÄ Salva tempos em results/
   
6. An√°lise estat√≠stica      make analyze
   ‚îú‚îÄ Calcula m√©tricas
   ‚îú‚îÄ Gera gr√°ficos
   ‚îî‚îÄ Cria tabela LaTeX
```

### Fase 4: Documenta√ß√£o
```
7. Compilar relat√≥rio       make report
   ‚îî‚îÄ Gera docs/relatorio.pdf
```

### Fase 5: Apresenta√ß√£o
```
8. Preparar slides          docs/apresentacao.md
9. Praticar apresenta√ß√£o    15-20 minutos
```

---

## üìÅ ESTRUTURA DE ARQUIVOS EXPLICADA

```
ppc/
‚îÇ
‚îú‚îÄ‚îÄ src/                              # C√≥digo fonte
‚îÇ   ‚îú‚îÄ‚îÄ sequential/recommender.c      # Vers√£o baseline (1 core)
‚îÇ   ‚îú‚îÄ‚îÄ openmp/recommender_omp.c      # Vers√£o OpenMP (N cores)
‚îÇ   ‚îú‚îÄ‚îÄ pthreads/recommender_pthread.c # Vers√£o Pthreads (N cores)
‚îÇ   ‚îî‚îÄ‚îÄ mpi/recommender_mpi.c         # Vers√£o MPI (N nodes)
‚îÇ
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ generate_data.py              # Gera avalia√ß√µes sint√©ticas
‚îÇ   ‚îú‚îÄ‚îÄ run_benchmark.sh              # Executa 10x cada vers√£o
‚îÇ   ‚îî‚îÄ‚îÄ analyze_results.py            # Calcula m√©tricas + gr√°ficos
‚îÇ
‚îú‚îÄ‚îÄ data/                             # Dados de entrada
‚îÇ   ‚îú‚îÄ‚îÄ ratings_small.txt             # 100√ó100 (teste r√°pido)
‚îÇ   ‚îú‚îÄ‚îÄ ratings_medium.txt            # 500√ó500 (benchmark)
‚îÇ   ‚îî‚îÄ‚îÄ ratings_large.txt             # 1000√ó1000 (an√°lise)
‚îÇ
‚îú‚îÄ‚îÄ results/                          # Resultados dos experimentos
‚îÇ   ‚îú‚îÄ‚îÄ sequential_times.txt          # 10 tempos da vers√£o seq
‚îÇ   ‚îú‚îÄ‚îÄ openmp_4t_times.txt           # 10 tempos OpenMP 4 threads
‚îÇ   ‚îú‚îÄ‚îÄ execution_time.png            # Gr√°fico tempo vs threads
‚îÇ   ‚îú‚îÄ‚îÄ speedup.png                   # Gr√°fico speedup
‚îÇ   ‚îú‚îÄ‚îÄ efficiency.png                # Gr√°fico efici√™ncia
‚îÇ   ‚îî‚îÄ‚îÄ results_table.tex             # Tabela para relat√≥rio
‚îÇ
‚îú‚îÄ‚îÄ build/                            # Execut√°veis compilados
‚îÇ   ‚îú‚îÄ‚îÄ recommender_seq               # Bin√°rio sequencial
‚îÇ   ‚îú‚îÄ‚îÄ recommender_omp               # Bin√°rio OpenMP
‚îÇ   ‚îú‚îÄ‚îÄ recommender_pthread           # Bin√°rio Pthreads
‚îÇ   ‚îî‚îÄ‚îÄ recommender_mpi               # Bin√°rio MPI
‚îÇ
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îú‚îÄ‚îÄ relatorio.tex                 # Relat√≥rio cient√≠fico (SBC)
‚îÇ   ‚îú‚îÄ‚îÄ apresentacao.md               # Slides para apresenta√ß√£o
‚îÇ   ‚îî‚îÄ‚îÄ sbc-template.sty              # Template SBC oficial
‚îÇ
‚îú‚îÄ‚îÄ Makefile                          # Automa√ß√£o de build/testes
‚îú‚îÄ‚îÄ run.sh                            # Menu interativo
‚îú‚îÄ‚îÄ check.sh                          # Verifica depend√™ncias
‚îÇ
‚îî‚îÄ‚îÄ Documenta√ß√£o:
    ‚îú‚îÄ‚îÄ README.md                     # Vis√£o geral
    ‚îú‚îÄ‚îÄ GUIA_PROJETO.md              # Guia completo
    ‚îú‚îÄ‚îÄ INSTRUCTIONS.md              # Instru√ß√µes t√©cnicas
    ‚îú‚îÄ‚îÄ RESUMO.txt                   # Resumo executivo
    ‚îî‚îÄ‚îÄ ENTENDIMENTO_PROJETO.md      # Este arquivo
```

---

## üéØ COMANDOS PRINCIPAIS EXPLICADOS

### Compila√ß√£o
```bash
make all          # Compila: sequencial + OpenMP + Pthreads + MPI
make sequential   # Compila apenas vers√£o sequencial
make openmp       # Compila apenas vers√£o OpenMP
make clean        # Remove execut√°veis
```

### Dados
```bash
make data         # Gera small, medium, large
python3 scripts/generate_data.py xlarge  # Gera dataset extra grande
```

### Testes
```bash
make test         # Teste r√°pido (1 execu√ß√£o, dataset small)
make benchmark    # Benchmark completo (10 exec √ó 4 configs)
make analyze      # Analisa resultados + gera gr√°ficos
```

### Execu√ß√£o Manual
```bash
# Sequencial
./build/recommender_seq data/ratings_medium.txt

# OpenMP com 8 threads
./build/recommender_omp data/ratings_medium.txt 8

# Pthreads com 4 threads
./build/recommender_pthread data/ratings_medium.txt 4

# MPI com 4 processos
mpirun -np 4 ./build/recommender_mpi data/ratings_medium.txt
```

### Documenta√ß√£o
```bash
make report       # Compila relat√≥rio LaTeX ‚Üí PDF
./run.sh          # Menu interativo completo
```

---

## üî¨ POR QUE PARALELIZAR?

### Exemplo Pr√°tico de Ganho

**Cen√°rio**: Calcular similaridade para 1000 produtos

#### Sequencial (1 core):
```
Compara√ß√µes: 1000 √ó 999 / 2 = 499.500
Tempo por compara√ß√£o: 0.01ms
Tempo total: 499.500 √ó 0.01ms = 4.995 segundos ‚âà 5 segundos
```

#### Paralelo (4 cores):
```
Cada core processa: 499.500 / 4 ‚âà 125.000 compara√ß√µes
Tempo por core: 125.000 √ó 0.01ms = 1.25 segundos
Speedup te√≥rico: 5s / 1.25s = 4x
Speedup real: ~3.2x (80% efici√™ncia devido a overhead)
```

### Overhead Paralelo
Fatores que reduzem efici√™ncia:
- **Sincroniza√ß√£o**: Threads precisam esperar umas pelas outras
- **Comunica√ß√£o**: Transfer√™ncia de dados entre processos (MPI)
- **Cria√ß√£o de threads**: Tempo para criar/destruir threads
- **Cache**: Conten√ß√£o quando m√∫ltiplos cores acessam mesma mem√≥ria

---

## üìä RESULTADOS ESPERADOS

### Speedup T√≠pico (Dataset Medium)

| Threads | Sequencial | OpenMP  | Pthreads | MPI     |
|---------|-----------|---------|----------|---------|
| 1       | 1.00x     | 1.00x   | 1.00x    | 1.00x   |
| 2       | 1.00x     | 1.85x   | 1.82x    | 1.71x   |
| 4       | 1.00x     | 3.41x   | 3.28x    | 2.93x   |
| 8       | 1.00x     | 5.67x   | 5.42x    | 4.81x   |

### Por Que OpenMP √© Mais R√°pido?
1. **Menos overhead**: Compilador otimiza automaticamente
2. **Scheduling din√¢mico**: Balanceamento de carga autom√°tico
3. **Mem√≥ria compartilhada**: Sem c√≥pia de dados
4. **Cache eficiente**: Melhor localidade de dados

### Por Que MPI √© Mais Lento (em 1 n√≥)?
1. **Overhead de comunica√ß√£o**: Broadcast e Gather
2. **C√≥pia de dados**: Serializa√ß√£o/desserializa√ß√£o
3. **Lat√™ncia**: Mesmo em mem√≥ria compartilhada
4. **Vantagem**: Escala para m√∫ltiplos computadores!

---

## üéì CONCEITOS DA DISCIPLINA APLICADOS

### ‚úÖ Processos e Threads
- Fork (conceitual)
- POSIX Threads (implementado)
- Mutex para exclus√£o m√∫tua
- Sincroniza√ß√£o com barreiras

### ‚úÖ Mem√≥ria Compartilhada
- OpenMP: diretivas #pragma
- Pthreads: controle expl√≠cito
- Particionamento de dados
- Scheduling (est√°tico vs din√¢mico)

### ‚úÖ Mem√≥ria Distribu√≠da
- MPI: message passing
- Broadcast (distribuir dados)
- Gather (coletar resultados)
- Balanceamento de carga

### ‚úÖ Avalia√ß√£o de Desempenho
- Tempo de execu√ß√£o
- Speedup
- Efici√™ncia
- Lei de Amdahl
- M√©trica de Karp-Flatt
- Escalabilidade

---

## üöÄ COMO USAR O PROJETO

### Para Desenvolvimento/Teste
```bash
./check.sh          # 1. Verificar depend√™ncias
make all            # 2. Compilar tudo
make data           # 3. Gerar dados
make test           # 4. Teste r√°pido
```

### Para Experimentos Completos
```bash
make benchmark      # 1. Executar 10x cada
make analyze        # 2. Gerar gr√°ficos
```

### Para Apresenta√ß√£o
```bash
make report         # 1. Compilar relat√≥rio
./run.sh            # 2. Menu interativo (demo ao vivo)
```

---

## üéØ OBJETIVO FINAL

Demonstrar que:
1. ‚úÖ **Paraleliza√ß√£o acelera** processamento de sistemas de recomenda√ß√£o
2. ‚úÖ **OpenMP √© eficiente** para mem√≥ria compartilhada
3. ‚úÖ **MPI escala** para computa√ß√£o distribu√≠da
4. ‚úÖ **M√©trica de desempenho** comprovam ganhos
5. ‚úÖ **Aplica√ß√£o real** (sistema da Amazon) beneficia-se de paraleliza√ß√£o

---

## üìö REFER√äNCIAS PRINCIPAIS

1. **Sarwar et al. (2001)** - Filtragem colaborativa item-item
2. **Linden et al. (2003)** - Sistema de recomenda√ß√£o da Amazon
3. **OpenMP 5.0** - Especifica√ß√£o da API
4. **MPI 3.1** - Padr√£o de passagem de mensagens

---

## ‚úÖ CHECKLIST DE COMPREENS√ÉO

Voc√™ entendeu o projeto se consegue responder:

- [ ] O que √© filtragem colaborativa item-item?
- [ ] Por que calcular similaridade de cosseno?
- [ ] Como OpenMP paraleliza o c√≥digo?
- [ ] Qual a diferen√ßa entre OpenMP e Pthreads?
- [ ] Por que MPI √© mais lento em 1 n√≥ mas escala melhor?
- [ ] O que √© speedup e efici√™ncia?
- [ ] Como interpretar a m√©trica de Karp-Flatt?
- [ ] O que `make test` faz exatamente?
- [ ] Como os gr√°ficos s√£o gerados?
- [ ] Qual o fluxo completo do projeto?

---

**Pronto! Agora voc√™ tem uma vis√£o completa do projeto!** üéì‚ú®
