# GUIA DO PROJETO - Sistema de RecomendaÃ§Ã£o da Amazon
## Projeto PrÃ¡tico de ParalelizaÃ§Ã£o e ConcorrÃªncia

---

## ğŸ“‹ RESUMO DO PROJETO

Este projeto implementa um **sistema de recomendaÃ§Ã£o de produtos para a Amazon** utilizando **filtragem colaborativa item-item** com trÃªs abordagens de paralelizaÃ§Ã£o:

1. **OpenMP** - MemÃ³ria compartilhada (mais simples e eficiente)
2. **Pthreads** - MemÃ³ria compartilhada (controle explÃ­cito)
3. **MPI** - MemÃ³ria distribuÃ­da (escalabilidade multi-nÃ³)

### Algoritmo Implementado
- **Filtragem Colaborativa Item-Item** com similaridade de cosseno
- Calcula matriz de similaridade entre produtos
- Gera recomendaÃ§Ãµes personalizadas baseadas em produtos similares

### Complexidade
- **Tempo**: O(nÂ²m) - n itens, m usuÃ¡rios
- **EspaÃ§o**: O(nm) - matriz esparsa de avaliaÃ§Ãµes

---

## ğŸ¯ OBJETIVOS ATENDIDOS (Etapas 2 e 3)

### âœ… Etapa 2 - ImplementaÃ§Ã£o Paralela
- [x] Algoritmo de filtragem colaborativa implementado
- [x] VersÃ£o sequencial (baseline)
- [x] ParalelizaÃ§Ã£o com OpenMP
- [x] ParalelizaÃ§Ã£o com Pthreads
- [x] ParalelizaÃ§Ã£o com MPI
- [x] CÃ³digo otimizado para alto desempenho (-O3)

### âœ… Etapa 3 - RelatÃ³rio Completo
- [x] **IntroduÃ§Ã£o**: MotivaÃ§Ã£o (e-commerce), problema (desempenho), abordagem atual, objetivos
- [x] **Referencial TeÃ³rico**: Algoritmo explicado, trabalhos relacionados citados
- [x] **Metodologia**: DecisÃµes de projeto, descriÃ§Ã£o do programa, hardware, experimentos
- [x] **Resultados**: GrÃ¡ficos (tempo, speedup, eficiÃªncia, Karp-Flatt) com IC 95%
- [x] **DiscussÃ£o**: AnÃ¡lise de desempenho, hardware, paralelizaÃ§Ã£o, overhead
- [x] **ConclusÃµes**: Retomada do problema, paralelizaÃ§Ã£o, resultados obtidos
- [x] **Formato SBC**: Template oficial da Sociedade Brasileira de ComputaÃ§Ã£o

---

## ğŸš€ INÃCIO RÃPIDO

### 1. Verificar Sistema
```bash
./check.sh
```

### 2. Instalar DependÃªncias (se necessÃ¡rio)
```bash
# Ubuntu/Debian
sudo apt install build-essential openmpi-bin libopenmpi-dev
pip3 install numpy matplotlib

# Fedora/RHEL
sudo dnf install gcc openmpi openmpi-devel
pip3 install numpy matplotlib
```

### 3. Compilar Tudo
```bash
make all
```

### 4. Gerar Dados de Teste
```bash
make data
```

### 5. Executar Teste RÃ¡pido
```bash
make test
```

### 6. Executar Benchmark Completo
```bash
make benchmark    # Executa 10 vezes cada configuraÃ§Ã£o
make analyze      # Gera grÃ¡ficos e anÃ¡lises
```

### 7. Compilar RelatÃ³rio
```bash
make report       # Requer LaTeX instalado
```

---

## ğŸ“Š MÃ‰TRICAS CALCULADAS

### 1. Tempo de ExecuÃ§Ã£o
- MÃ©dia de 10 execuÃ§Ãµes
- Intervalo de confianÃ§a 95% (t-Student)
- GrÃ¡fico comparativo entre versÃµes

### 2. Speedup
```
Sp = T_sequencial / T_paralelo
```
- Speedup ideal: linear (Sp = p)
- GrÃ¡fico: speedup vs threads/processos

### 3. EficiÃªncia
```
Ep = Sp / p
```
- EficiÃªncia ideal: 100% (Ep = 1)
- Indica utilizaÃ§Ã£o dos recursos

### 4. FraÃ§Ã£o Serial (Karp-Flatt)
```
e = (1/Sp - 1/p) / (1 - 1/p)
```
- Estima porcentagem de cÃ³digo nÃ£o paralelizÃ¡vel
- Valores baixos = boa paralelizaÃ§Ã£o

---

## ğŸ“ ESTRUTURA DO PROJETO

```
ppc/
â”œâ”€â”€ README.md                    # DocumentaÃ§Ã£o geral
â”œâ”€â”€ INSTRUCTIONS.md              # InstruÃ§Ãµes detalhadas
â”œâ”€â”€ GUIA_PROJETO.md             # Este arquivo
â”œâ”€â”€ Makefile                     # AutomaÃ§Ã£o de build
â”œâ”€â”€ run.sh                       # Script interativo
â”œâ”€â”€ check.sh                     # VerificaÃ§Ã£o do sistema
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ sequential/              # VersÃ£o baseline
â”‚   â”‚   â””â”€â”€ recommender.c
â”‚   â”œâ”€â”€ openmp/                  # ParalelizaÃ§Ã£o OpenMP
â”‚   â”‚   â””â”€â”€ recommender_omp.c
â”‚   â”œâ”€â”€ pthreads/                # ParalelizaÃ§Ã£o Pthreads
â”‚   â”‚   â””â”€â”€ recommender_pthread.c
â”‚   â””â”€â”€ mpi/                     # ParalelizaÃ§Ã£o MPI
â”‚       â””â”€â”€ recommender_mpi.c
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ generate_data.py         # Gerador de datasets
â”‚   â”œâ”€â”€ run_benchmark.sh         # AutomaÃ§Ã£o de experimentos
â”‚   â””â”€â”€ analyze_results.py       # AnÃ¡lise e grÃ¡ficos
â”‚
â”œâ”€â”€ data/                        # Datasets gerados
â”‚   â”œâ”€â”€ ratings_small.txt        # 100x100, 1K ratings
â”‚   â”œâ”€â”€ ratings_medium.txt       # 500x500, 10K ratings
â”‚   â””â”€â”€ ratings_large.txt        # 1000x1000, 50K ratings
â”‚
â”œâ”€â”€ results/                     # Resultados dos experimentos
â”‚   â”œâ”€â”€ *_times.txt              # Tempos de execuÃ§Ã£o
â”‚   â”œâ”€â”€ *.png                    # GrÃ¡ficos gerados
â”‚   â””â”€â”€ results_table.tex        # Tabela LaTeX
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ relatorio.tex            # RelatÃ³rio completo (SBC)
â”‚   â””â”€â”€ sbc-template.sty         # Template oficial
â”‚
â””â”€â”€ build/                       # ExecutÃ¡veis compilados
    â”œâ”€â”€ recommender_seq
    â”œâ”€â”€ recommender_omp
    â”œâ”€â”€ recommender_pthread
    â””â”€â”€ recommender_mpi
```

---

## ğŸ”¬ EXPERIMENTOS REALIZADOS

### ConfiguraÃ§Ãµes Testadas
- **Threads/Processos**: 1, 2, 4, 8
- **Datasets**: Small, Medium, Large
- **ExecuÃ§Ãµes**: 10 vezes cada (mÃ©dia + IC 95%)

### VariÃ¡veis Analisadas
1. Impacto do nÃºmero de threads/processos
2. Impacto do tamanho da entrada
3. ComparaÃ§Ã£o entre bibliotecas (OpenMP vs Pthreads vs MPI)
4. Overhead de paralelizaÃ§Ã£o
5. Escalabilidade

---

## ğŸ“ˆ RESULTADOS ESPERADOS

### Speedup TÃ­pico
- **2 threads**: ~1.8x
- **4 threads**: ~3.2x
- **8 threads**: ~5.5x

### EficiÃªncia
- **2 threads**: ~90%
- **4 threads**: ~80%
- **8 threads**: ~68%

### ComparaÃ§Ã£o de Bibliotecas
1. **OpenMP**: Melhor desempenho (menos overhead)
2. **Pthreads**: Similar ao OpenMP (mais controle)
3. **MPI**: Overhead maior (mas escala multi-nÃ³)

---

## ğŸ“ CONCEITOS APLICADOS DA DISCIPLINA

### Processos e Threads
- [x] Fork (conceito discutido)
- [x] Threads POSIX (Pthreads)
- [x] ExclusÃ£o mÃºtua (mutex para progresso)
- [x] SincronizaÃ§Ã£o (barreiras implÃ­citas)

### MemÃ³ria Compartilhada
- [x] OpenMP (diretivas #pragma)
- [x] Pthreads (controle explÃ­cito)
- [x] Particionamento de dados
- [x] Scheduling (dinÃ¢mico vs estÃ¡tico)

### MemÃ³ria DistribuÃ­da
- [x] MPI (Message Passing)
- [x] Broadcast (distribuiÃ§Ã£o de dados)
- [x] Gather (coleta de resultados)
- [x] ComunicaÃ§Ã£o ponto-a-ponto

### AvaliaÃ§Ã£o de Desempenho
- [x] Tempo de execuÃ§Ã£o
- [x] Speedup
- [x] EficiÃªncia
- [x] Lei de Amdahl
- [x] MÃ©trica de Karp-Flatt
- [x] Escalabilidade

### Projeto de Algoritmos Paralelos
- [x] IdentificaÃ§Ã£o de paralelismo
- [x] DecomposiÃ§Ã£o de dados
- [x] Balanceamento de carga
- [x] MinimizaÃ§Ã£o de comunicaÃ§Ã£o
- [x] AnÃ¡lise de overhead

---

## ğŸ’¡ DECISÃ•ES DE PROJETO

### Por que Item-Item e nÃ£o User-User?
- Matriz de similaridade entre itens muda menos
- Mais escalÃ¡vel para muitos usuÃ¡rios
- Usado pela Amazon em produÃ§Ã£o (Linden et al., 2003)

### Por que Similaridade de Cosseno?
- MÃ©trica padrÃ£o para filtragem colaborativa
- RÃ¡pida de calcular
- Funciona bem com dados esparsos

### Por que C e nÃ£o Python?
- Performance crÃ­tica (C ~100x mais rÃ¡pido)
- Melhor controle de memÃ³ria
- Bibliotecas de paralelizaÃ§Ã£o nativas

### EstratÃ©gia de ParalelizaÃ§Ã£o
- **Paralelizar o loop externo**: Melhor balanceamento
- **Scheduling dinÃ¢mico**: Compensar desbalanceamento
- **Matriz simÃ©trica**: Calcular apenas triÃ¢ngulo superior

---

## ğŸ¯ COMO APRESENTAR/DEFENDER

### Estrutura da ApresentaÃ§Ã£o (SugestÃ£o)
1. **IntroduÃ§Ã£o (2 min)**
   - Problema: RecomendaÃ§Ã£o em larga escala na Amazon
   - Desafio: CÃ¡lculo computacionalmente intensivo
   
2. **Algoritmo (3 min)**
   - Filtragem colaborativa item-item
   - CÃ¡lculo de similaridade (cosseno)
   - Complexidade O(nÂ²m)
   
3. **ParalelizaÃ§Ã£o (5 min)**
   - IdentificaÃ§Ã£o de paralelismo (matriz de similaridade)
   - OpenMP: Pragma paralelo
   - Pthreads: DivisÃ£o manual
   - MPI: DistribuiÃ§Ã£o por linhas
   
4. **Resultados (5 min)**
   - GrÃ¡ficos de tempo, speedup, eficiÃªncia
   - AnÃ¡lise de Karp-Flatt
   - ComparaÃ§Ã£o entre abordagens
   
5. **ConclusÃµes (2 min)**
   - Speedup de atÃ© Xx alcanÃ§ado
   - OpenMP mais eficiente para memÃ³ria compartilhada
   - MPI essencial para clusters

### Perguntas Esperadas
**P: Por que a eficiÃªncia diminui com mais threads?**
R: Overhead de sincronizaÃ§Ã£o, contenÃ§Ã£o de cache, saturaÃ§Ã£o de memÃ³ria

**P: Por que MPI Ã© mais lento?**
R: Overhead de comunicaÃ§Ã£o (broadcast/gather), mas escala multi-nÃ³

**P: E se a matriz nÃ£o couber na memÃ³ria?**
R: Usar estruturas esparsas, processamento por blocos, ou frameworks distribuÃ­dos (Spark)

**P: Como isso se compara com sistemas reais?**
R: Amazon usa tÃ©cnicas mais avanÃ§adas (deep learning), mas princÃ­pios similares

---

## ğŸ“š REFERÃŠNCIAS IMPORTANTES

### Principais Papers Citados
1. **Sarwar et al. (2001)** - Item-based CF original
2. **Linden et al. (2003)** - Sistema da Amazon
3. **Gemulla et al. (2011)** - ParalelizaÃ§Ã£o com SGD
4. **Yu et al. (2014)** - Escalabilidade com Spark

### DocumentaÃ§Ã£o TÃ©cnica
- OpenMP Specification 5.0
- POSIX Threads Programming
- MPI: A Message-Passing Interface Standard

---

## âš¡ DICAS FINAIS

### Para Melhor Desempenho
```bash
# Compilar com otimizaÃ§Ãµes nativas
gcc -O3 -march=native -fopenmp ...

# Fixar threads em nÃºcleos
export OMP_PROC_BIND=true
export OMP_PLACES=cores

# Usar dataset grande para amortizar overhead
./recommender_omp data/ratings_large.txt 8
```

### Para Debugging
```bash
# Habilitar warnings
gcc -Wall -Wextra ...

# Verificar race conditions (OpenMP)
gcc -fsanitize=thread ...

# Profiling
perf record ./recommender_omp data.txt 4
perf report
```

### Para ApresentaÃ§Ã£o
1. Compilar tudo antes: `make all`
2. Gerar dados: `make data`
3. Rodar benchmark: `make benchmark && make analyze`
4. Preparar slides com grÃ¡ficos de `results/`
5. DemonstraÃ§Ã£o ao vivo: `./run.sh` (opÃ§Ã£o 2 - teste rÃ¡pido)

---

## âœ… CHECKLIST FINAL

### Antes da Entrega
- [ ] CÃ³digo compila sem erros/warnings
- [ ] Todos os testes passam (`make test`)
- [ ] Benchmark executado (`make benchmark`)
- [ ] GrÃ¡ficos gerados (`make analyze`)
- [ ] RelatÃ³rio compilado (`make report`)
- [ ] CÃ³digo comentado e limpo
- [ ] README atualizado com resultados reais

### Arquivos para Entregar
- [ ] CÃ³digo fonte (`src/`)
- [ ] Scripts (`scripts/`)
- [ ] RelatÃ³rio PDF (`docs/relatorio.pdf`)
- [ ] Resultados e grÃ¡ficos (`results/`)
- [ ] README.md completo

---

## ğŸ†˜ TROUBLESHOOTING

### Problema: MPI nÃ£o encontrado
```bash
sudo apt install openmpi-bin libopenmpi-dev
# Ou adicionar ao PATH
export PATH=/usr/lib64/openmpi/bin:$PATH
```

### Problema: Python sem numpy
```bash
pip3 install --user numpy matplotlib scipy
```

### Problema: Resultados inconsistentes
```bash
# Fechar outros programas
# Desabilitar turbo boost (para resultados consistentes)
echo 1 | sudo tee /sys/devices/system/cpu/intel_pstate/no_turbo

# Executar mais vezes (aumentar NUM_RUNS)
```

### Problema: CompilaÃ§Ã£o lenta
```bash
# Usar compilaÃ§Ã£o paralela
make -j$(nproc)
```

---

## ğŸ“ CONTATO E SUPORTE

- **DocumentaÃ§Ã£o**: Leia README.md e INSTRUCTIONS.md
- **CÃ³digo**: ComentÃ¡rios detalhados em cada arquivo .c
- **DÃºvidas**: Revise os conceitos da disciplina no cronograma

---

## ğŸ† BOA SORTE NA APRESENTAÃ‡ÃƒO!

**Lembre-se**: Este projeto demonstra domÃ­nio completo de:
- âœ… ParalelizaÃ§Ã£o (OpenMP, Pthreads, MPI)
- âœ… AnÃ¡lise de desempenho (todas as mÃ©tricas)
- âœ… AplicaÃ§Ã£o prÃ¡tica (sistema real de recomendaÃ§Ã£o)
- âœ… DocumentaÃ§Ã£o cientÃ­fica (formato SBC)

**VocÃª estÃ¡ preparado(a)!** ğŸš€
