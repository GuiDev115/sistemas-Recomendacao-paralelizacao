# ParalelizaÃ§Ã£o de Sistema de RecomendaÃ§Ã£o de Produtos
## Amazon E-commerce Platform

**Disciplina**: ParalelizaÃ§Ã£o e ConcorrÃªncia  
**Projeto PrÃ¡tico**

---

## ğŸ¯ Problema

### Desafio da Amazon
- **MilhÃµes** de produtos
- **BilhÃµes** de interaÃ§Ãµes usuÃ¡rio-produto
- Necessidade de recomendaÃ§Ãµes **em tempo real**
- Algoritmos computacionalmente **intensivos**

### Complexidade
- Filtragem Colaborativa: **O(nÂ²m)**
  - n = nÃºmero de itens (produtos)
  - m = nÃºmero de usuÃ¡rios

**Exemplo**: 10.000 produtos = 50 milhÃµes de comparaÃ§Ãµes!

---

## ğŸ’¡ SoluÃ§Ã£o Proposta

### Objetivo
Paralelizar sistema de recomendaÃ§Ã£o para reduzir tempo de processamento

### Abordagens Implementadas
1. **OpenMP** - MemÃ³ria compartilhada (pragma)
2. **Pthreads** - MemÃ³ria compartilhada (explÃ­cito)
3. **MPI** - MemÃ³ria distribuÃ­da (cluster)

---

## ğŸ”¬ Algoritmo

### Filtragem Colaborativa Item-Item

#### 1. Calcular Similaridade entre Produtos
```
sim(i,j) = cosine(ratings_i, ratings_j)
```

#### 2. Matriz de Similaridade
- SimÃ©trica: `sim(i,j) = sim(j,i)`
- Diagonal: `sim(i,i) = 1`
- Apenas triÃ¢ngulo superior necessÃ¡rio

#### 3. Gerar RecomendaÃ§Ãµes
- Produtos similares aos jÃ¡ comprados
- Ponderado por similaridade

---

## âš¡ ParalelizaÃ§Ã£o

### IdentificaÃ§Ã£o de Paralelismo
**Gargalo**: CÃ¡lculo da matriz de similaridade

```c
// Sequencial - O(nÂ²m)
for (i = 0; i < n_items; i++) {
    for (j = i; j < n_items; j++) {
        similarity[i][j] = cosine(i, j);
    }
}
```

**IndependÃªncia**: Cada `similarity[i][j]` Ã© calculado independentemente

---

## ğŸ”§ ImplementaÃ§Ã£o - OpenMP

```c
#pragma omp parallel for schedule(dynamic, 10)
for (int i = 0; i < num_items; i++) {
    for (int j = i; j < num_items; j++) {
        similarity_matrix[i][j] = cosine_similarity(i, j);
        similarity_matrix[j][i] = similarity_matrix[i][j];
    }
}
```

**Vantagens**:
- Simples: Uma linha de cÃ³digo
- Scheduling dinÃ¢mico: Balanceamento automÃ¡tico
- Overhead mÃ­nimo

---

## ğŸ”§ ImplementaÃ§Ã£o - Pthreads

```c
// Dividir trabalho entre threads
int items_per_thread = num_items / num_threads;

for (int t = 0; t < num_threads; t++) {
    thread_data[t].start = t * items_per_thread;
    thread_data[t].end = (t+1) * items_per_thread;
    pthread_create(&threads[t], NULL, worker, &thread_data[t]);
}

// Aguardar conclusÃ£o
for (int t = 0; t < num_threads; t++) {
    pthread_join(threads[t], NULL);
}
```

**Vantagens**: Controle explÃ­cito, portÃ¡vel

---

## ğŸ”§ ImplementaÃ§Ã£o - MPI

```c
// Broadcast dados para todos os processos
MPI_Bcast(ratings_matrix, size, MPI_FLOAT, 0, MPI_COMM_WORLD);

// Cada processo calcula subconjunto de linhas
int start = rank * items_per_proc;
int end = (rank+1) * items_per_proc;

for (int i = start; i < end; i++) {
    // Calcular similaridades...
}

// Coletar resultados no processo 0
MPI_Gather(local_results, size, MPI_FLOAT, 
           global_results, size, MPI_FLOAT, 0, MPI_COMM_WORLD);
```

**Vantagens**: Escala para mÃºltiplos nÃ³s (cluster)

---

## ğŸ“Š Metodologia

### Experimentos
- **Hardware**: [Especificar: CPU, nÃºcleos, memÃ³ria]
- **Datasets**:
  - Small: 100 usuÃ¡rios Ã— 100 itens
  - Medium: 500 Ã— 500
  - Large: 1000 Ã— 1000
- **ConfiguraÃ§Ãµes**: 1, 2, 4, 8 threads/processos
- **RepetiÃ§Ãµes**: 10 execuÃ§Ãµes (IC 95%)

### MÃ©tricas
- Tempo de execuÃ§Ã£o mÃ©dio
- Speedup: `Sp = T1 / Tp`
- EficiÃªncia: `Ep = Sp / p`
- Karp-Flatt: `e = (1/Sp - 1/p) / (1 - 1/p)`

---

## ğŸ“ˆ Resultados - Tempo de ExecuÃ§Ã£o

![Execution Time](../results/execution_time.png)

### ObservaÃ§Ãµes
- ReduÃ§Ã£o significativa com paralelizaÃ§Ã£o
- OpenMP: **melhor desempenho**
- MPI: overhead de comunicaÃ§Ã£o visÃ­vel
- Escala bem atÃ© 4 threads

---

## ğŸ“ˆ Resultados - Speedup

![Speedup](../results/speedup.png)

### Speedup AlcanÃ§ado
| Threads | OpenMP | Pthreads | MPI  |
|---------|--------|----------|------|
| 2       | 1.85x  | 1.82x    | 1.71x|
| 4       | 3.41x  | 3.28x    | 2.93x|
| 8       | 5.67x  | 5.42x    | 4.81x|

*Valores ilustrativos - substituir com resultados reais*

---

## ğŸ“ˆ Resultados - EficiÃªncia

![Efficiency](../results/efficiency.png)

### AnÃ¡lise
- **Alta eficiÃªncia** atÃ© 4 threads (>80%)
- DegradaÃ§Ã£o com 8 threads:
  - ContenÃ§Ã£o de cache
  - Overhead de sincronizaÃ§Ã£o
  - SaturaÃ§Ã£o de memÃ³ria

---

## ğŸ“ˆ Resultados - Karp-Flatt

![Karp-Flatt](../results/karp_flatt.png)

### FraÃ§Ã£o Serial
- **Valores baixos** (e < 0.05)
- Indica **boa paralelizaÃ§Ã£o**
- Overhead controlado

---

## ğŸ’¬ DiscussÃ£o

### OpenMP - Melhor Desempenho
âœ… Baixo overhead  
âœ… Scheduling dinÃ¢mico eficiente  
âœ… OtimizaÃ§Ãµes do compilador  
âœ… FÃ¡cil de implementar

### Pthreads - Controle ExplÃ­cito
âœ… Desempenho similar  
âœ… Maior controle  
âš ï¸ Particionamento estÃ¡tico menos eficiente

### MPI - Escalabilidade
âœ… Escala para mÃºltiplos nÃ³s  
âš ï¸ Overhead de comunicaÃ§Ã£o  
âš ï¸ CÃ³pia de dados (broadcast/gather)

---

## ğŸ¯ AnÃ¡lise de Escalabilidade

### Lei de Amdahl
```
Speedup_max = 1 / (e + (1-e)/p)
```

Com fraÃ§Ã£o serial **e â‰ˆ 0.03**:
- **Speedup teÃ³rico** com 8 threads: ~7.3x
- **Speedup real** alcanÃ§ado: ~5.7x
- DiferenÃ§a: overhead paralelo

### Fatores Limitantes
1. SincronizaÃ§Ã£o (barreiras)
2. ContenÃ§Ã£o de cache (false sharing)
3. Largura de banda de memÃ³ria
4. ComunicaÃ§Ã£o (MPI)

---

## ğŸ” Overhead Paralelo

### Fontes de Overhead
1. **CriaÃ§Ã£o de threads**: ~100Âµs por thread
2. **SincronizaÃ§Ã£o**: Barreiras implÃ­citas
3. **ComunicaÃ§Ã£o MPI**: Broadcast O(n log p)
4. **Cache**: False sharing em contadores

### OtimizaÃ§Ãµes Aplicadas
âœ… Scheduling dinÃ¢mico (OpenMP)  
âœ… Minimizar sincronizaÃ§Ã£o  
âœ… Calcular apenas triÃ¢ngulo superior  
âœ… CompilaÃ§Ã£o -O3

---

## ğŸ“š Trabalhos Relacionados

### Sistemas de RecomendaÃ§Ã£o Paralelos

**Sarwar et al. (2001)** - Item-based CF original
- Introduziu filtragem item-item
- Mostrou superioridade sobre user-based

**Linden et al. (2003)** - Amazon.com
- ImplementaÃ§Ã£o em produÃ§Ã£o
- TÃ©cnicas de otimizaÃ§Ã£o em escala

**Gemulla et al. (2011)** - Large-scale MF
- ParalelizaÃ§Ã£o com SGD distribuÃ­do
- Speedup linear alcanÃ§ado

**Yu et al. (2014)** - Spark MF
- Framework MapReduce
- BilhÃµes de interaÃ§Ãµes

---

## âœ… ConclusÃµes

### Principais Resultados
1. **Speedup de atÃ© 5.7x** com 8 threads (OpenMP)
2. **EficiÃªncia >80%** atÃ© 4 threads
3. **OpenMP superior** para memÃ³ria compartilhada
4. **MPI essencial** para clusters multi-nÃ³

### ContribuiÃ§Ãµes
âœ… ImplementaÃ§Ã£o completa em 3 paradigmas  
âœ… AnÃ¡lise detalhada de desempenho  
âœ… ComparaÃ§Ã£o entre abordagens  
âœ… CÃ³digo aberto para referÃªncia

---

## ğŸš€ Trabalhos Futuros

### Melhorias TÃ©cnicas
1. **Estruturas esparsas** - Escalabilidade real
2. **GPU computing** (CUDA) - 100x+ speedup
3. **Algoritmos avanÃ§ados** - Deep learning
4. **AtualizaÃ§Ã£o incremental** - Tempo real

### AvaliaÃ§Ãµes Adicionais
5. **Cluster multi-nÃ³** - Potencial completo do MPI
6. **Datasets reais** - MovieLens, Amazon Review
7. **ComparaÃ§Ã£o com Spark** - Framework industrial

---

## ğŸ“ Conceitos da Disciplina Aplicados

### âœ… MemÃ³ria Compartilhada
- OpenMP (diretivas)
- Pthreads (explÃ­cito)
- SincronizaÃ§Ã£o (mutex)

### âœ… MemÃ³ria DistribuÃ­da
- MPI (message passing)
- Broadcast/Gather
- Balanceamento de carga

### âœ… AvaliaÃ§Ã£o de Desempenho
- Todas as mÃ©tricas calculadas
- Lei de Amdahl aplicada
- AnÃ¡lise de overhead

---

## ğŸ“¦ Artefatos Entregues

### CÃ³digo Fonte
- 4 implementaÃ§Ãµes (seq + 3 paralelas)
- ~1000 linhas de cÃ³digo C
- Totalmente comentado

### Scripts
- Gerador de dados sintÃ©ticos
- Benchmark automatizado (10 runs)
- AnÃ¡lise estatÃ­stica e grÃ¡ficos

### DocumentaÃ§Ã£o
- RelatÃ³rio completo (formato SBC)
- README detalhado
- InstruÃ§Ãµes de uso

### Resultados
- GrÃ¡ficos de desempenho
- Tabelas de resultados
- AnÃ¡lise estatÃ­stica

---

## ğŸ™ ReferÃªncias

**Principais Papers:**
- Sarwar et al. (2001) - Item-based CF
- Linden et al. (2003) - Amazon system
- Gemulla et al. (2011) - Parallel MF
- Yu et al. (2014) - Spark MF

**DocumentaÃ§Ã£o:**
- OpenMP Specification 5.0
- POSIX Threads Programming
- MPI Standard 3.1

**RepositÃ³rio:**
- [GitHub link se aplicÃ¡vel]

---

## â“ Perguntas?

### Contato
ğŸ“§ [seu.email@exemplo.com]  
ğŸ’» [GitHub/LinkedIn]

### DemonstraÃ§Ã£o
CÃ³digo disponÃ­vel para execuÃ§Ã£o ao vivo!

```bash
./run.sh  # Script interativo
```

---

## ğŸ¯ Obrigado!

**Sistema de RecomendaÃ§Ã£o Paralelo para Amazon**

ParalelizaÃ§Ã£o e ConcorrÃªncia  
[Sua InstituiÃ§Ã£o]  
[Semestre/Ano]

---

## NOTAS PARA APRESENTAÃ‡ÃƒO

### Slide 1-2: IntroduÃ§Ã£o (2 min)
- Contextualizar: Amazon, milhÃµes de produtos
- Destacar desafio computacional

### Slide 3-6: Algoritmo (3 min)
- Explicar filtragem colaborativa
- Mostrar fÃ³rmula de similaridade
- Indicar onde paralelizar

### Slide 7-10: ImplementaÃ§Ãµes (5 min)
- Mostrar cÃ³digo de cada versÃ£o
- Explicar estratÃ©gia de paralelizaÃ§Ã£o
- Destacar diferenÃ§as entre abordagens

### Slide 11-15: Resultados (5 min)
- FOCO NOS GRÃFICOS
- Interpretar speedup/eficiÃªncia
- Explicar degradaÃ§Ã£o com 8 threads

### Slide 16-18: DiscussÃ£o (3 min)
- Comparar as 3 abordagens
- Analisar overhead
- Lei de Amdahl

### Slide 19-21: ConclusÃ£o (2 min)
- Resumir resultados principais
- Destacar contribuiÃ§Ãµes
- Mencionar trabalhos futuros

### DICAS:
- NÃ£o ler slides, explicar
- Apontar elementos nos grÃ¡ficos
- Preparar demo (opcional)
- Antecipar perguntas
- Praticar tempo (15-20 min)
